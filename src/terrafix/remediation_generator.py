"""
AWS Bedrock client for Terraform remediation generation.

This module constructs prompts with full context about compliance failures
and existing Terraform configuration, then uses Claude Opus 4.5 via AWS
Bedrock to generate compliant fixes in proper HCL format.

The generator maintains a library of Terraform documentation snippets for
common resource types to improve fix quality.

Implementation follows AWS Bedrock documentation:
- https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-claude.html
- https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html

And Anthropic prompting best practices:
- Uses system prompts for persona/role definition
- Leverages XML tags for structured context
- Uses low temperature for deterministic, consistent output

Usage:
    from terrafix.remediation_generator import TerraformRemediationGenerator

    generator = TerraformRemediationGenerator(
        model_id="anthropic.claude-opus-4-5-20251101-v1:0",
        region="us-west-2"
    )

    fix = generator.generate_fix(
        failure=failure,
        current_config=terraform_content,
        resource_block=resource_block,
        module_context=context
    )

    print(fix["fixed_config"])
"""

import json
from typing import Any

import boto3
from botocore.config import Config
from botocore.exceptions import ClientError
from pydantic import BaseModel, Field

from terrafix.errors import BedrockError
from terrafix.logging_config import get_logger, log_with_context
from terrafix.vanta_client import Failure

logger = get_logger(__name__)

# Maximum tokens for prompt to avoid exceeding model limits
# Claude Opus 4.5 supports up to 200K input tokens, using conservative limit
MAX_PROMPT_TOKENS = 100000


class RemediationFix(BaseModel):
    """
    Terraform remediation fix generated by Claude.

    Attributes:
        fixed_config: Complete updated Terraform file content
        explanation: Human-readable explanation of changes
        changed_attributes: List of attributes that were modified
        reasoning: Why these changes address the compliance failure
        confidence: high/medium/low confidence in the fix
        breaking_changes: Any potential breaking changes or migration notes
        additional_requirements: Any manual steps required after applying
    """

    fixed_config: str = Field(..., description="Updated Terraform configuration")
    explanation: str = Field(..., description="Human-readable explanation")
    changed_attributes: list[str] = Field(
        default_factory=list,
        description="Modified attributes",
    )
    reasoning: str = Field(
        default="",
        description="Why these changes fix the failure",
    )
    confidence: str = Field(..., description="high/medium/low")
    breaking_changes: str = Field(
        default="None identified",
        description="Potential breaking changes",
    )
    additional_requirements: str = Field(
        default="None",
        description="Manual steps required",
    )


class TerraformRemediationGenerator:
    """
    Generates Terraform configuration fixes using Claude via Bedrock.

    Uses AWS Bedrock to invoke Claude Opus 4.5 with carefully constructed
    prompts containing failure context and Terraform documentation.

    Per AWS Bedrock documentation, Claude 3.7 Sonnet and Claude 4 models have
    a 60-minute timeout period for inference calls. This client is configured
    with appropriate read timeout settings.

    Reference:
        https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html

    Attributes:
        bedrock_client: Boto3 Bedrock Runtime client configured with extended timeout
        model_id: Claude model identifier (e.g., "anthropic.claude-opus-4-5-20251101-v1:0")
        system_prompt: System prompt defining the AI assistant's role and behavior
    """

    # System prompt following Anthropic best practices for role definition
    # Per AWS docs: "A system prompt lets you provide context and instructions
    # to Anthropic Claude, such as specifying a particular goal or role."
    DEFAULT_SYSTEM_PROMPT: str = """You are a senior DevOps engineer and compliance expert specializing in Terraform and AWS security best practices.

Your expertise includes:
- Infrastructure as Code (IaC) with Terraform 1.0+
- AWS security controls and compliance frameworks (SOC 2, HIPAA, PCI-DSS)
- HCL syntax and Terraform style conventions
- Cloud security architecture and remediation strategies

Your task is to analyze compliance failures and generate precise, minimal Terraform configuration fixes that:
1. Address the specific compliance requirement completely
2. Follow Terraform best practices and style conventions
3. Preserve existing functionality and dependencies
4. Include appropriate documentation comments

You always respond with valid JSON containing the fix details. You never include explanatory text outside the JSON structure."""

    def __init__(
        self,
        model_id: str = "anthropic.claude-opus-4-5-20251101-v1:0",
        region: str = "us-west-2",
        read_timeout_seconds: int = 3600,
    ) -> None:
        """
        Initialize Bedrock Claude client with appropriate timeout configuration.

        Per AWS Bedrock documentation for Claude 3.7 Sonnet and Claude 4 models:
        "The timeout period for inference calls [...] is 60 minutes. By default,
        AWS SDK clients timeout after 1 minute. We recommend that you increase
        the read timeout period of your AWS SDK client to at least 60 minutes."

        Args:
            model_id: Claude model ID. Default is Claude Opus 4.5.
                      Format: anthropic.claude-{variant}-{version}-v{api_version}:0
            region: AWS region for Bedrock. Must be a region where Bedrock is available.
            read_timeout_seconds: Read timeout in seconds for API calls.
                                  Default is 3600 (60 minutes) per AWS recommendation.

        Raises:
            botocore.exceptions.NoRegionError: If region is invalid or unavailable
            botocore.exceptions.NoCredentialsError: If AWS credentials not configured

        Example:
            >>> generator = TerraformRemediationGenerator()
            >>> generator = TerraformRemediationGenerator(
            ...     model_id="anthropic.claude-sonnet-4-20250514-v1:0",
            ...     region="us-east-1",
            ...     read_timeout_seconds=1800  # 30 minutes for simpler tasks
            ... )
        """
        # Configure boto3 with extended read timeout per AWS documentation
        # Reference: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html
        bedrock_config = Config(
            read_timeout=read_timeout_seconds,
            connect_timeout=60,  # 1 minute for initial connection
            retries={
                "max_attempts": 3,
                "mode": "adaptive",  # Adaptive retry mode handles throttling
            },
        )

        self.bedrock_client = boto3.client(
            service_name="bedrock-runtime",
            region_name=region,
            config=bedrock_config,
        )
        self.model_id = model_id
        self.system_prompt = self.DEFAULT_SYSTEM_PROMPT

        log_with_context(
            logger,
            "info",
            "Initialized Bedrock client",
            model_id=self.model_id,
            region=region,
            read_timeout_seconds=read_timeout_seconds,
        )

    def generate_fix(
        self,
        failure: Failure,
        current_config: str,
        resource_block: dict[str, Any],
        module_context: dict[str, Any],
    ) -> RemediationFix:
        """
        Generate Terraform configuration fix.

        Constructs a detailed prompt with failure context and current config,
        invokes Claude via Bedrock, and parses the response.

        Args:
            failure: Vanta test failure details
            current_config: Current Terraform file content
            resource_block: Specific resource block that failed
            module_context: Surrounding module context

        Returns:
            RemediationFix with fixed config and metadata

        Raises:
            BedrockError: If Bedrock API call fails

        Example:
            >>> fix = generator.generate_fix(
            ...     failure=failure,
            ...     current_config=content,
            ...     resource_block=block,
            ...     module_context=context
            ... )
        """
        log_with_context(
            logger,
            "info",
            "Generating Terraform fix",
            test_id=failure.test_id,
            resource_arn=failure.resource_arn,
            resource_type=failure.resource_type,
        )

        prompt = self._construct_prompt(
            failure,
            current_config,
            resource_block,
            module_context,
        )

        # Check prompt size and truncate if needed
        if len(prompt) > MAX_PROMPT_TOKENS * 4:  # Rough character estimate
            log_with_context(
                logger,
                "warning",
                "Prompt exceeds recommended size, truncating",
                original_size=len(prompt),
            )
            # Truncate current_config if it's too large
            if len(current_config) > 10000:
                current_config = current_config[:10000] + "\n\n... [truncated]"

        try:
            response = self._invoke_claude(prompt)
            fix = self._parse_response(response)

            log_with_context(
                logger,
                "info",
                "Successfully generated fix",
                test_id=failure.test_id,
                confidence=fix.confidence,
                changed_attributes=fix.changed_attributes,
            )

            return fix

        except ClientError as e:
            error_code = e.response.get("Error", {}).get("Code", "Unknown")
            request_id = e.response.get("ResponseMetadata", {}).get("RequestId")

            log_with_context(
                logger,
                "error",
                "Bedrock API error",
                error_code=error_code,
                request_id=request_id,
                error_message=str(e),
            )

            # Determine if error is retryable
            retryable = error_code in [
                "ThrottlingException",
                "ServiceUnavailableException",
                "InternalServerException",
            ]

            raise BedrockError(
                f"Bedrock API error: {e}",
                error_code=error_code,
                request_id=request_id,
                retryable=retryable,
            ) from e

    def _construct_prompt(
        self,
        failure: Failure,
        current_config: str,
        resource_block: dict[str, Any],
        module_context: dict[str, Any],
    ) -> str:
        """
        Construct detailed prompt for Claude using XML tags per Anthropic guidelines.

        Per Anthropic documentation: "Claude models support the use of XML tags to
        structure and delineate your prompts. Use descriptive tag names for optimal
        results."

        Reference:
            https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags

        The prompt structure follows Anthropic best practices:
        - Clear separation of context from instructions
        - XML tags for structured data sections
        - Explicit output format specification
        - Critical constraints clearly stated

        Args:
            failure: Vanta failure details containing test information and required state
            current_config: Current Terraform file content to be modified
            resource_block: Specific resource block that failed compliance
            module_context: Surrounding module context for dependency awareness

        Returns:
            Complete prompt string formatted with XML tags for Claude
        """
        terraform_docs = self._get_terraform_docs_for_resource(failure.resource_type)

        # Construct prompt using XML tags per Anthropic guidelines
        # XML tags help Claude parse structured information more accurately
        prompt = f"""<compliance_failure>
<test_name>{failure.test_name}</test_name>
<severity>{failure.severity}</severity>
<framework>{failure.framework}</framework>
<resource_arn>{failure.resource_arn}</resource_arn>
<resource_type>{failure.resource_type}</resource_type>
<failure_reason>{failure.failure_reason}</failure_reason>

<current_state>
{json.dumps(failure.current_state, indent=2)}
</current_state>

<required_state>
{json.dumps(failure.required_state, indent=2)}
</required_state>
</compliance_failure>

<current_terraform_configuration>
{current_config}
</current_terraform_configuration>

<resource_block_context>
{json.dumps(resource_block, indent=2)}
</resource_block_context>

<module_context>
{json.dumps(module_context, indent=2)}
</module_context>

<terraform_documentation>
{terraform_docs}
</terraform_documentation>

<task>
Generate a Terraform configuration fix that:
1. Addresses the compliance failure completely
2. Maintains existing resource dependencies
3. Follows Terraform best practices (style guide, naming conventions)
4. Uses proper HCL syntax compatible with Terraform 1.0+
5. Preserves any existing tags, lifecycle rules, or metadata
6. Includes appropriate inline comments explaining security controls
</task>

<output_format>
Respond ONLY with valid JSON matching this exact schema. Do not include any text before or after the JSON object:

{{
  "fixed_config": "Complete updated Terraform file content as a string",
  "explanation": "Human-readable explanation of what changes were made and why",
  "changed_attributes": ["List", "of", "modified", "attribute", "names"],
  "reasoning": "Technical explanation of why these specific changes address the compliance failure",
  "confidence": "high OR medium OR low",
  "breaking_changes": "Description of any breaking changes or 'None identified' if none",
  "additional_requirements": "Manual steps required after applying or 'None' if none"
}}
</output_format>

<critical_constraints>
- The fix MUST be syntactically valid HCL that passes terraform validate
- Do NOT change resource names, identifiers, or logical names
- Do NOT remove existing configuration unless strictly necessary for compliance
- Preserve all existing comments and formatting where possible
- Use terraform fmt style conventions (2-space indentation, aligned equals signs)
- Apply the minimum changes necessary to resolve the compliance issue
- All string values in the JSON must have special characters properly escaped
</critical_constraints>

Generate the JSON response:"""

        log_with_context(
            logger,
            "debug",
            "Constructed prompt with XML tags",
            prompt_length=len(prompt),
            test_id=failure.test_id,
        )

        return prompt

    def _get_terraform_docs_for_resource(self, resource_type: str) -> str:
        """
        Get relevant Terraform documentation for resource type.

        Returns documentation snippets for common AWS resource types.
        In production, this could fetch from Terraform Registry API.

        Args:
            resource_type: AWS resource type (AWS::S3::Bucket, etc.)

        Returns:
            Terraform documentation snippet
        """
        docs_map: dict[str, str] = {
            "AWS::S3::Bucket": """
## aws_s3_bucket Block Public Access

```hcl
resource "aws_s3_bucket_public_access_block" "example" {
  bucket = aws_s3_bucket.example.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}
```

## aws_s3_bucket Server-Side Encryption

```hcl
resource "aws_s3_bucket_server_side_encryption_configuration" "example" {
  bucket = aws_s3_bucket.example.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}
```

## aws_s3_bucket Versioning

```hcl
resource "aws_s3_bucket_versioning" "example" {
  bucket = aws_s3_bucket.example.id

  versioning_configuration {
    status = "Enabled"
  }
}
```
""",
            "AWS::IAM::Role": """
## aws_iam_role with Trust Policy

```hcl
resource "aws_iam_role" "example" {
  name = "example-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "lambda.amazonaws.com"
      }
    }]
  })
  
  # Recommended: Set maximum session duration
  max_session_duration = 3600
  
  tags = {
    Environment = "production"
  }
}
```

## aws_iam_role_policy_attachment

```hcl
resource "aws_iam_role_policy_attachment" "example" {
  role       = aws_iam_role.example.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}
```
""",
            "AWS::EC2::SecurityGroup": """
## aws_security_group Best Practices

```hcl
resource "aws_security_group" "example" {
  name        = "example-sg"
  description = "Security group for example"
  vpc_id      = aws_vpc.main.id

  # Avoid overly permissive rules
  ingress {
    description = "HTTPS from VPC"
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = [aws_vpc.main.cidr_block]
  }

  egress {
    description = "Allow outbound"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "example-sg"
  }
}
```
""",
            "AWS::RDS::DBInstance": """
## aws_db_instance Security Settings

```hcl
resource "aws_db_instance" "example" {
  identifier = "example-db"
  
  # Enable encryption
  storage_encrypted = true
  kms_key_id       = aws_kms_key.db.arn
  
  # Enable backups
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  
  # Enable deletion protection
  deletion_protection = true
  
  # Enable auto minor version upgrades
  auto_minor_version_upgrade = true
  
  # Enable enhanced monitoring
  monitoring_interval = 60
  monitoring_role_arn = aws_iam_role.rds_monitoring.arn
  
  # Enable CloudWatch logs
  enabled_cloudwatch_logs_exports = ["error", "general", "slowquery"]
}
```
""",
        }

        return docs_map.get(resource_type, "# No specific docs available")

    def _invoke_claude(self, prompt: str) -> dict[str, Any]:
        """
        Call Bedrock to invoke Claude Opus 4.5 using the Messages API.

        Implements the Anthropic Claude Messages API as documented:
        https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html

        Request body structure follows AWS Bedrock specification:
        - anthropic_version: Required API version string
        - max_tokens: Maximum tokens to generate (required)
        - system: System prompt for role/context definition (Claude 2.1+)
        - messages: Array of user/assistant message turns
        - temperature: Randomness control (0-1, lower = more deterministic)
        - top_p: Nucleus sampling threshold
        - top_k: Limits sampling to top K options
        - stop_sequences: Custom sequences that halt generation

        Args:
            prompt: Constructed prompt with failure context and XML tags

        Returns:
            Raw Bedrock API response containing:
            - content: Array of content blocks with generated text
            - stop_reason: Why generation stopped ("end_turn", "stop_sequence", "max_tokens")
            - usage: Token usage statistics

        Raises:
            BedrockError: If Bedrock API call fails (wraps ClientError)
        """
        # Construct request body per AWS Bedrock Messages API specification
        # Reference: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html
        body: dict[str, Any] = {
            # Required: API version for Bedrock
            "anthropic_version": "bedrock-2023-05-31",
            # Required: Maximum tokens to generate
            # Per AWS docs: "We recommend a limit of 4,000 tokens for optimal performance"
            "max_tokens": 4096,
            # System prompt: Defines the assistant's role and behavior
            # Per AWS docs: "A system prompt lets you provide context and instructions
            # to Anthropic Claude, such as specifying a particular goal or role."
            # Note: Requires Claude 2.1 or greater
            "system": self.system_prompt,
            # Messages array: The conversation history
            # Each message has 'role' ("user" or "assistant") and 'content'
            "messages": [
                {
                    "role": "user",
                    # Content can be string or array of content blocks
                    # Using string shorthand for single text block
                    "content": prompt,
                }
            ],
            # Temperature: Controls randomness (0 = deterministic, 1 = creative)
            # Using low temperature for consistent, reliable code generation
            "temperature": 0.1,
            # top_p: Nucleus sampling - cumulative probability threshold
            # Per AWS docs: "Alter either temperature or top_p, but not both"
            # We keep both but with complementary values for code generation
            "top_p": 0.95,
            # top_k: Limits sampling to top K most likely tokens
            # Per AWS docs: "Use top_k to remove long tail low probability responses"
            # Value of 250 balances diversity with reliability
            "top_k": 250,
            # stop_sequences: Custom strings that halt generation
            # Per AWS docs: "Sequences that will cause the model to stop generating"
            # Using these to ensure clean JSON output termination
            "stop_sequences": [
                "\n\n\n",  # Triple newline indicates end of JSON
                "```",  # Prevent markdown code block wrapping
            ],
        }

        log_with_context(
            logger,
            "debug",
            "Invoking Bedrock Claude API",
            model_id=self.model_id,
            max_tokens=body["max_tokens"],
            temperature=body["temperature"],
            top_p=body["top_p"],
            top_k=body["top_k"],
            has_system_prompt=bool(body.get("system")),
        )

        response = self.bedrock_client.invoke_model(
            modelId=self.model_id,
            body=json.dumps(body),
            contentType="application/json",
            accept="application/json",
        )

        response_body = json.loads(response["body"].read())

        # Log response metadata for debugging
        log_with_context(
            logger,
            "debug",
            "Received Bedrock response",
            stop_reason=response_body.get("stop_reason"),
            usage=response_body.get("usage"),
        )

        return response_body

    def _parse_response(self, response: dict[str, Any]) -> RemediationFix:
        """
        Extract structured fix from Claude's response.

        Handles various response formats and validates required fields.

        Args:
            response: Raw Bedrock response

        Returns:
            Parsed RemediationFix

        Raises:
            BedrockError: If response cannot be parsed or is invalid
        """
        content = response.get("content", [])
        if not content:
            raise BedrockError(
                "Empty Claude response",
                retryable=False,
            )

        text = content[0].get("text", "").strip()

        log_with_context(
            logger,
            "debug",
            "Parsing Claude response",
            response_length=len(text),
        )

        # Claude may wrap JSON in markdown code blocks
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            text = text.split("```")[1].split("```")[0].strip()

        try:
            parsed = json.loads(text)
        except json.JSONDecodeError as e:
            log_with_context(
                logger,
                "error",
                "Invalid JSON from Claude",
                error=str(e),
                response_text=text[:500],
            )
            raise BedrockError(
                f"Invalid JSON from Claude: {e}",
                retryable=False,
            ) from e

        # Validate required fields
        required = ["fixed_config", "explanation", "confidence"]
        for field in required:
            if field not in parsed:
                raise BedrockError(
                    f"Missing required field in Claude response: {field}",
                    retryable=False,
                )

        # Create RemediationFix with validation
        try:
            return RemediationFix(**parsed)
        except Exception as e:
            log_with_context(
                logger,
                "error",
                "Failed to parse RemediationFix",
                error=str(e),
                parsed_keys=list(parsed.keys()),
            )
            raise BedrockError(
                f"Failed to parse RemediationFix: {e}",
                retryable=False,
            ) from e

